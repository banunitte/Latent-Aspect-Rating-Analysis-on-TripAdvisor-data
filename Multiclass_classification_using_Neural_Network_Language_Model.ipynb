{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rlOf5AhzRVUf",
    "outputId": "42c60268-1c61-4525-84ee-7b41f80615fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive',force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KqALdeFhSBCW",
    "outputId": "43ea0cb8-1587-4979-a3be-599295c5d08b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\n",
      "  Downloading https://files.pythonhosted.org/packages/00/92/a05b76a692ac08d470ae5c23873cf1c9a041532f1ee065e74b374f218306/contractions-0.0.25-py2.py3-none-any.whl\n",
      "Collecting textsearch\n",
      "  Downloading https://files.pythonhosted.org/packages/42/a8/03407021f9555043de5492a2bd7a35c56cc03c2510092b5ec018cae1bbf1/textsearch-0.0.17-py2.py3-none-any.whl\n",
      "Collecting Unidecode\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
      "\u001b[K     |████████████████████████████████| 245kB 7.1MB/s \n",
      "\u001b[?25hCollecting pyahocorasick\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/9f/f0d8e8850e12829eea2e778f1c90e3c53a9a799b7f412082a5d21cd19ae1/pyahocorasick-1.4.0.tar.gz (312kB)\n",
      "\u001b[K     |████████████████████████████████| 317kB 39.0MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
      "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.0-cp36-cp36m-linux_x86_64.whl size=81698 sha256=58a0bc073084b5cd98c06efb1e432b01560f712361f45723e59bf50d0f67e1d0\n",
      "  Stored in directory: /root/.cache/pip/wheels/0a/90/61/87a55f5b459792fbb2b7ba6b31721b06ff5cf6bde541b40994\n",
      "Successfully built pyahocorasick\n",
      "Installing collected packages: Unidecode, pyahocorasick, textsearch, contractions\n",
      "Successfully installed Unidecode-1.1.1 contractions-0.0.25 pyahocorasick-1.4.0 textsearch-0.0.17\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i2tH_V27SDwW",
    "outputId": "a550411a-70ce-44cd-d84d-90475b6bca52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.3.0\n",
      "Eager mode:  True\n",
      "Hub version:  0.10.0\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "## Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "import contractions\n",
    "import numpy as np\n",
    "import re\n",
    "import tqdm\n",
    "import unicodedata\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xW_SRUAhSLRP"
   },
   "outputs": [],
   "source": [
    "## load training and testing dataset\n",
    "train = pd.read_csv('/content/gdrive/My Drive/lily/train.csv')\n",
    "test = pd.read_csv('/content/gdrive/My Drive/lily/test.csv')\n",
    "\n",
    "output_map = {'Animal Diseases': 0,\n",
    " 'Bacterial Infections and Mycoses': 3,\n",
    " 'Cardiovascular Diseases': 1,\n",
    " 'Chemically-Induced Disorders': 2,\n",
    " 'Congenital Hereditary and Neonatal Diseases and Abnormalities': 4,\n",
    " 'Digestive System Diseases': 5,\n",
    " 'Disorders of Environmental Origin': 22,\n",
    " 'Endocrine System Diseases': 6,\n",
    " 'Eye Diseases': 7,\n",
    " 'Female Urogenital Diseases and Pregnancy Complications': 8,\n",
    " 'Hemic and Lymphatic Diseases': 9,\n",
    " 'Immune System Diseases': 10,\n",
    " 'Male Urogenital Diseases': 11,\n",
    " 'Musculoskeletal Diseases': 24,\n",
    " 'Neoplasms': 12,\n",
    " 'Nervous System Diseases': 13,\n",
    " 'Nutritional and Metabolic Diseases': 14,\n",
    " 'Occupational Diseases': 15,\n",
    " 'Otorhinolaryngologic Diseases': 16,\n",
    " 'Parasitic Diseases': 17,\n",
    " 'Pathological Conditions and Signs and Symptoms': 18,\n",
    " 'Respiratory Tract Diseases': 19,\n",
    " 'Skin and Connective Tissue Diseases': 25,\n",
    " 'Stomatognathic Diseases': 20,\n",
    " 'Virus Diseases': 21,\n",
    " 'Wounds and Injuries': 23}\n",
    "\n",
    "train['categories'] = train['categories'].map(output_map)\n",
    "test['categories'] = test['categories'].map(output_map)\n",
    "validation = test.sample(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOMoiE2SBfZB"
   },
   "source": [
    "Basic Text Pre-processing\n",
    "We do minimal text pre-processing here since we are using deep learning models and not count-based methods. Steps include the following:\n",
    "\n",
    "\n",
    "\n",
    "Converting accented characters\n",
    "* Removal of stopwords\n",
    "*   Fixing contractions\n",
    "*   Removing special characters\n",
    "*   Converting accented characters\n",
    "\n",
    "Note : For some models we don't use any pre-processing like BERT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QP3QtHKKSFqN"
   },
   "outputs": [],
   "source": [
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "def pre_process_corpus(docs):\n",
    "    norm_docs = []\n",
    "    for doc in tqdm.tqdm(docs):\n",
    "        doc = doc.translate(doc.maketrans(\"\\n\\t\\r\", \"   \"))\n",
    "        doc = doc.lower()\n",
    "        doc = remove_accented_chars(doc)\n",
    "        doc = contractions.fix(doc)\n",
    "        # lower case and remove special characters\\whitespaces\n",
    "        doc = re.sub(r'[^a-zA-Z0-9\\s]', ' ', doc, re.I|re.A)\n",
    "        doc = re.sub(' +', ' ', doc)\n",
    "        doc = doc.strip()  \n",
    "        norm_docs.append(doc)\n",
    "    return norm_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iq084V0zSY5H",
    "outputId": "3fb8508c-e93d-425f-f305-42edb02ff0c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43916/43916 [00:07<00:00, 5670.51it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 5494.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.6 s, sys: 60.6 ms, total: 8.67 s\n",
      "Wall time: 8.67 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_content = pre_process_corpus(list(train['abstract']))\n",
    "valid_content = pre_process_corpus(list(validation['abstract']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tnhbjt1SBsY5"
   },
   "source": [
    "convert target variable to one hot encoding since its a multiclass classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_HCJMfoS2v_"
   },
   "outputs": [],
   "source": [
    "train_rating = np_utils.to_categorical(train['categories'])\n",
    "valid_rating = np_utils.to_categorical(validation['categories'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUkjezsrBweD"
   },
   "source": [
    "Building input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KdCCX_c6TL4l"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_content, train_rating))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hC4bU2HZUi4u"
   },
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices((valid_content, valid_rating))\n",
    "test_dataset = test_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"nnm.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpFoMrHnB2ZS"
   },
   "source": [
    "Build a NNLM Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O5yExSpITRnV"
   },
   "outputs": [],
   "source": [
    "model = \"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\"\n",
    "hub_layer = hub.KerasLayer(model, output_shape=[128], input_shape=[], \n",
    "                           dtype=tf.string, trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N6n7cF_AB4l0"
   },
   "source": [
    "Build Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46SdLfdMTUau",
    "outputId": "6f57758b-c1bd-4d10-ac25-07a2e7ac83cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 128)               124642688 \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 26)                3354      \n",
      "=================================================================\n",
      "Total params: 124,679,066\n",
      "Trainable params: 124,679,066\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.15))\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.15))\n",
    "model.add(tf.keras.layers.Dense(26, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_qbGFvFCAoz"
   },
   "source": [
    "Define callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x80nPexKCAOO"
   },
   "outputs": [],
   "source": [
    "filepath = '/content/gdrive/My Drive/lily/'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=filepath,\n",
    "    save_weights_only=False,\n",
    "    save_best_only=True)\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                      patience=5,\n",
    "                                      restore_best_weights=True,\n",
    "                                      verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZaF-uIA-CDAc"
   },
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dljSQu5eTXQd",
    "outputId": "96d1dda8-24f4-438b-958d-ff410c8d08ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "687/687 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9975INFO:tensorflow:Assets written to: /content/gdrive/My Drive/lily/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/lily/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687/687 [==============================] - 92s 134ms/step - loss: 0.0111 - accuracy: 0.9975 - val_loss: 6.4342 - val_accuracy: 0.6440\n",
      "Epoch 2/1000\n",
      "687/687 [==============================] - 84s 123ms/step - loss: 0.0090 - accuracy: 0.9977 - val_loss: 6.5357 - val_accuracy: 0.6554\n",
      "Epoch 3/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 6.8640 - val_accuracy: 0.6422\n",
      "Epoch 4/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0115 - accuracy: 0.9970 - val_loss: 6.4465 - val_accuracy: 0.6588\n",
      "Epoch 5/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 6.5515 - val_accuracy: 0.6558\n",
      "Epoch 6/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0088 - accuracy: 0.9980 - val_loss: 7.2039 - val_accuracy: 0.6542\n",
      "Epoch 7/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 6.9669 - val_accuracy: 0.6622\n",
      "Epoch 8/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 7.2271 - val_accuracy: 0.6522\n",
      "Epoch 9/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0108 - accuracy: 0.9977 - val_loss: 6.9256 - val_accuracy: 0.6582\n",
      "Epoch 10/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 6.9834 - val_accuracy: 0.6638\n",
      "Epoch 11/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0079 - accuracy: 0.9981 - val_loss: 7.1078 - val_accuracy: 0.6508\n",
      "Epoch 12/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 6.9176 - val_accuracy: 0.6576\n",
      "Epoch 13/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0100 - accuracy: 0.9977 - val_loss: 7.6630 - val_accuracy: 0.6452\n",
      "Epoch 14/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0105 - accuracy: 0.9977 - val_loss: 6.8535 - val_accuracy: 0.6518\n",
      "Epoch 15/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 6.9794 - val_accuracy: 0.6602\n",
      "Epoch 16/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0091 - accuracy: 0.9977 - val_loss: 7.0064 - val_accuracy: 0.6618\n",
      "Epoch 17/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 7.7068 - val_accuracy: 0.6572\n",
      "Epoch 18/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0085 - accuracy: 0.9983 - val_loss: 6.9084 - val_accuracy: 0.6590\n",
      "Epoch 19/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0089 - accuracy: 0.9980 - val_loss: 8.0455 - val_accuracy: 0.6428\n",
      "Epoch 20/1000\n",
      "687/687 [==============================] - 84s 122ms/step - loss: 0.0099 - accuracy: 0.9977 - val_loss: 7.1193 - val_accuracy: 0.6702\n",
      "Epoch 21/1000\n",
      "687/687 [==============================] - 84s 122ms/step - loss: 0.0095 - accuracy: 0.9979 - val_loss: 6.7566 - val_accuracy: 0.6594\n",
      "Epoch 22/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0094 - accuracy: 0.9980 - val_loss: 6.8186 - val_accuracy: 0.6698\n",
      "Epoch 23/1000\n",
      "687/687 [==============================] - 84s 122ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 6.8904 - val_accuracy: 0.6798\n",
      "Epoch 24/1000\n",
      "687/687 [==============================] - 84s 122ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 7.1775 - val_accuracy: 0.6770\n",
      "Epoch 25/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 6.9881 - val_accuracy: 0.6796\n",
      "Epoch 26/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 7.1764 - val_accuracy: 0.6778\n",
      "Epoch 27/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 7.5068 - val_accuracy: 0.6762\n",
      "Epoch 28/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 7.4797 - val_accuracy: 0.6694\n",
      "Epoch 29/1000\n",
      "687/687 [==============================] - 84s 122ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 7.8578 - val_accuracy: 0.6688\n",
      "Epoch 30/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0096 - accuracy: 0.9981 - val_loss: 7.8069 - val_accuracy: 0.6568\n",
      "Epoch 31/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 7.7739 - val_accuracy: 0.6642\n",
      "Epoch 32/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0088 - accuracy: 0.9979 - val_loss: 7.9245 - val_accuracy: 0.6664\n",
      "Epoch 33/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0083 - accuracy: 0.9978 - val_loss: 7.5435 - val_accuracy: 0.6670\n",
      "Epoch 34/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0074 - accuracy: 0.9984 - val_loss: 7.0675 - val_accuracy: 0.6776\n",
      "Epoch 35/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0095 - accuracy: 0.9980 - val_loss: 7.4720 - val_accuracy: 0.6694\n",
      "Epoch 36/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 7.4053 - val_accuracy: 0.6594\n",
      "Epoch 37/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 7.4309 - val_accuracy: 0.6712\n",
      "Epoch 38/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0077 - accuracy: 0.9985 - val_loss: 8.0856 - val_accuracy: 0.6686\n",
      "Epoch 39/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0067 - accuracy: 0.9985 - val_loss: 7.1445 - val_accuracy: 0.6792\n",
      "Epoch 40/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 7.9146 - val_accuracy: 0.6716\n",
      "Epoch 41/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 8.1432 - val_accuracy: 0.6696\n",
      "Epoch 42/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0081 - accuracy: 0.9984 - val_loss: 7.6196 - val_accuracy: 0.6686\n",
      "Epoch 43/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 7.5424 - val_accuracy: 0.6690\n",
      "Epoch 44/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0071 - accuracy: 0.9987 - val_loss: 7.6550 - val_accuracy: 0.6692\n",
      "Epoch 45/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 7.1940 - val_accuracy: 0.6792\n",
      "Epoch 46/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 7.3450 - val_accuracy: 0.6794\n",
      "Epoch 47/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 7.1094 - val_accuracy: 0.6742\n",
      "Epoch 48/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 7.5462 - val_accuracy: 0.6780\n",
      "Epoch 49/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 8.1631 - val_accuracy: 0.6714\n",
      "Epoch 50/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 8.1393 - val_accuracy: 0.6712\n",
      "Epoch 51/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 7.8996 - val_accuracy: 0.6746\n",
      "Epoch 52/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0060 - accuracy: 0.9989 - val_loss: 7.8386 - val_accuracy: 0.6782\n",
      "Epoch 53/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 7.9935 - val_accuracy: 0.6666\n",
      "Epoch 54/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 7.9598 - val_accuracy: 0.6644\n",
      "Epoch 55/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 8.1873 - val_accuracy: 0.6738\n",
      "Epoch 56/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0076 - accuracy: 0.9987 - val_loss: 8.0986 - val_accuracy: 0.6778\n",
      "Epoch 57/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 8.2109 - val_accuracy: 0.6734\n",
      "Epoch 58/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0067 - accuracy: 0.9985 - val_loss: 8.3100 - val_accuracy: 0.6720\n",
      "Epoch 59/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0079 - accuracy: 0.9986 - val_loss: 8.1826 - val_accuracy: 0.6734\n",
      "Epoch 60/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 8.7880 - val_accuracy: 0.6736\n",
      "Epoch 61/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0077 - accuracy: 0.9985 - val_loss: 8.2675 - val_accuracy: 0.6796\n",
      "Epoch 62/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0065 - accuracy: 0.9989 - val_loss: 8.1565 - val_accuracy: 0.6842\n",
      "Epoch 63/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0074 - accuracy: 0.9988 - val_loss: 8.1044 - val_accuracy: 0.6762\n",
      "Epoch 64/1000\n",
      "687/687 [==============================] - 82s 120ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 8.2893 - val_accuracy: 0.6684\n",
      "Epoch 65/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0073 - accuracy: 0.9986 - val_loss: 8.1968 - val_accuracy: 0.6780\n",
      "Epoch 66/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0071 - accuracy: 0.9987 - val_loss: 8.0454 - val_accuracy: 0.6810\n",
      "Epoch 67/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 8.2875 - val_accuracy: 0.6704\n",
      "Epoch 68/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 7.9154 - val_accuracy: 0.6808\n",
      "Epoch 69/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 8.0599 - val_accuracy: 0.6714\n",
      "Epoch 70/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0061 - accuracy: 0.9990 - val_loss: 8.0613 - val_accuracy: 0.6686\n",
      "Epoch 71/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 7.9159 - val_accuracy: 0.6760\n",
      "Epoch 72/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 7.8687 - val_accuracy: 0.6778\n",
      "Epoch 73/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 8.1512 - val_accuracy: 0.6818\n",
      "Epoch 74/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 7.8668 - val_accuracy: 0.6752\n",
      "Epoch 75/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 8.0058 - val_accuracy: 0.6732\n",
      "Epoch 76/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0067 - accuracy: 0.9987 - val_loss: 8.3237 - val_accuracy: 0.6726\n",
      "Epoch 77/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0075 - accuracy: 0.9987 - val_loss: 8.3588 - val_accuracy: 0.6728\n",
      "Epoch 78/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 8.3849 - val_accuracy: 0.6802\n",
      "Epoch 79/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 8.8228 - val_accuracy: 0.6766\n",
      "Epoch 80/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 8.7398 - val_accuracy: 0.6750\n",
      "Epoch 81/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 8.8211 - val_accuracy: 0.6770\n",
      "Epoch 82/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 8.6805 - val_accuracy: 0.6778\n",
      "Epoch 83/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 8.8345 - val_accuracy: 0.6756\n",
      "Epoch 84/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 9.0391 - val_accuracy: 0.6740\n",
      "Epoch 85/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 9.0755 - val_accuracy: 0.6742\n",
      "Epoch 86/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 8.9365 - val_accuracy: 0.6752\n",
      "Epoch 87/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 8.8191 - val_accuracy: 0.6714\n",
      "Epoch 88/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 8.9763 - val_accuracy: 0.6812\n",
      "Epoch 89/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 8.8475 - val_accuracy: 0.6786\n",
      "Epoch 90/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 9.1042 - val_accuracy: 0.6778\n",
      "Epoch 91/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 9.2741 - val_accuracy: 0.6778\n",
      "Epoch 92/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 9.3254 - val_accuracy: 0.6762\n",
      "Epoch 93/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 9.4082 - val_accuracy: 0.6734\n",
      "Epoch 94/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 8.9766 - val_accuracy: 0.6868\n",
      "Epoch 95/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 9.2988 - val_accuracy: 0.6782\n",
      "Epoch 96/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 9.6260 - val_accuracy: 0.6788\n",
      "Epoch 97/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 9.4881 - val_accuracy: 0.6702\n",
      "Epoch 98/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 9.2311 - val_accuracy: 0.6774\n",
      "Epoch 99/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 9.4679 - val_accuracy: 0.6734\n",
      "Epoch 100/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 9.7073 - val_accuracy: 0.6788\n",
      "Epoch 101/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 9.3040 - val_accuracy: 0.6788\n",
      "Epoch 102/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 9.7039 - val_accuracy: 0.6750\n",
      "Epoch 103/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 9.6024 - val_accuracy: 0.6754\n",
      "Epoch 104/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 9.7216 - val_accuracy: 0.6780\n",
      "Epoch 105/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0081 - accuracy: 0.9987 - val_loss: 9.7019 - val_accuracy: 0.6798\n",
      "Epoch 106/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0074 - accuracy: 0.9987 - val_loss: 9.4765 - val_accuracy: 0.6804\n",
      "Epoch 107/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0055 - accuracy: 0.9990 - val_loss: 9.8288 - val_accuracy: 0.6614\n",
      "Epoch 108/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 9.6628 - val_accuracy: 0.6872\n",
      "Epoch 109/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 9.4733 - val_accuracy: 0.6802\n",
      "Epoch 110/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 10.0968 - val_accuracy: 0.6790\n",
      "Epoch 111/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0076 - accuracy: 0.9986 - val_loss: 9.2725 - val_accuracy: 0.6794\n",
      "Epoch 112/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 9.9112 - val_accuracy: 0.6780\n",
      "Epoch 113/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 9.2211 - val_accuracy: 0.6836\n",
      "Epoch 114/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0060 - accuracy: 0.9989 - val_loss: 9.6185 - val_accuracy: 0.6830\n",
      "Epoch 115/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0066 - accuracy: 0.9989 - val_loss: 9.0104 - val_accuracy: 0.6714\n",
      "Epoch 116/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 9.0751 - val_accuracy: 0.6782\n",
      "Epoch 117/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 9.3881 - val_accuracy: 0.6808\n",
      "Epoch 118/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 9.3558 - val_accuracy: 0.6814\n",
      "Epoch 119/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 9.5028 - val_accuracy: 0.6804\n",
      "Epoch 120/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0055 - accuracy: 0.9990 - val_loss: 9.6691 - val_accuracy: 0.6774\n",
      "Epoch 121/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 9.7658 - val_accuracy: 0.6838\n",
      "Epoch 122/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 9.8869 - val_accuracy: 0.6836\n",
      "Epoch 123/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 10.3029 - val_accuracy: 0.6820\n",
      "Epoch 124/1000\n",
      "687/687 [==============================] - 82s 120ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 10.1383 - val_accuracy: 0.6876\n",
      "Epoch 125/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0075 - accuracy: 0.9988 - val_loss: 10.0438 - val_accuracy: 0.6824\n",
      "Epoch 126/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 10.1310 - val_accuracy: 0.6760\n",
      "Epoch 127/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 10.5645 - val_accuracy: 0.6790\n",
      "Epoch 128/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 9.8522 - val_accuracy: 0.6820\n",
      "Epoch 129/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0062 - accuracy: 0.9989 - val_loss: 10.1485 - val_accuracy: 0.6770\n",
      "Epoch 130/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0060 - accuracy: 0.9990 - val_loss: 9.6204 - val_accuracy: 0.6768\n",
      "Epoch 131/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 9.6004 - val_accuracy: 0.6800\n",
      "Epoch 132/1000\n",
      "687/687 [==============================] - 82s 120ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 9.8983 - val_accuracy: 0.6880\n",
      "Epoch 133/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 9.5640 - val_accuracy: 0.6896\n",
      "Epoch 134/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 9.7935 - val_accuracy: 0.6824\n",
      "Epoch 135/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0086 - accuracy: 0.9989 - val_loss: 9.6909 - val_accuracy: 0.6776\n",
      "Epoch 136/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0072 - accuracy: 0.9988 - val_loss: 10.0600 - val_accuracy: 0.6820\n",
      "Epoch 137/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 9.8328 - val_accuracy: 0.6850\n",
      "Epoch 138/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 9.5098 - val_accuracy: 0.6796\n",
      "Epoch 139/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 9.7181 - val_accuracy: 0.6874\n",
      "Epoch 140/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 9.7864 - val_accuracy: 0.6814\n",
      "Epoch 141/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 9.7482 - val_accuracy: 0.6758\n",
      "Epoch 142/1000\n",
      "687/687 [==============================] - 82s 120ms/step - loss: 0.0063 - accuracy: 0.9989 - val_loss: 10.1269 - val_accuracy: 0.6744\n",
      "Epoch 143/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 10.2688 - val_accuracy: 0.6764\n",
      "Epoch 144/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 10.2189 - val_accuracy: 0.6738\n",
      "Epoch 145/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 10.0271 - val_accuracy: 0.6856\n",
      "Epoch 146/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 9.8439 - val_accuracy: 0.6836\n",
      "Epoch 147/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0052 - accuracy: 0.9992 - val_loss: 10.0862 - val_accuracy: 0.6862\n",
      "Epoch 148/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0063 - accuracy: 0.9990 - val_loss: 10.2505 - val_accuracy: 0.6818\n",
      "Epoch 149/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 9.9981 - val_accuracy: 0.6858\n",
      "Epoch 150/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 10.0847 - val_accuracy: 0.6832\n",
      "Epoch 151/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 10.8354 - val_accuracy: 0.6758\n",
      "Epoch 152/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0063 - accuracy: 0.9989 - val_loss: 10.3822 - val_accuracy: 0.6836\n",
      "Epoch 153/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 10.2769 - val_accuracy: 0.6836\n",
      "Epoch 154/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 10.7986 - val_accuracy: 0.6818\n",
      "Epoch 155/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 10.5842 - val_accuracy: 0.6850\n",
      "Epoch 156/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 10.6741 - val_accuracy: 0.6784\n",
      "Epoch 157/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 11.0753 - val_accuracy: 0.6870\n",
      "Epoch 158/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 11.0123 - val_accuracy: 0.6836\n",
      "Epoch 159/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 10.7198 - val_accuracy: 0.6894\n",
      "Epoch 160/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0058 - accuracy: 0.9993 - val_loss: 10.2023 - val_accuracy: 0.6846\n",
      "Epoch 161/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 10.4584 - val_accuracy: 0.6872\n",
      "Epoch 162/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 11.0052 - val_accuracy: 0.6754\n",
      "Epoch 163/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0063 - accuracy: 0.9990 - val_loss: 10.6613 - val_accuracy: 0.6828\n",
      "Epoch 164/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 10.5133 - val_accuracy: 0.6820\n",
      "Epoch 165/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 11.1149 - val_accuracy: 0.6860\n",
      "Epoch 166/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 10.9159 - val_accuracy: 0.6836\n",
      "Epoch 167/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 11.4431 - val_accuracy: 0.6804\n",
      "Epoch 168/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 10.9661 - val_accuracy: 0.6792\n",
      "Epoch 169/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 11.2005 - val_accuracy: 0.6774\n",
      "Epoch 170/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 10.9547 - val_accuracy: 0.6842\n",
      "Epoch 171/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 11.3654 - val_accuracy: 0.6844\n",
      "Epoch 172/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 11.3817 - val_accuracy: 0.6826\n",
      "Epoch 173/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 11.1595 - val_accuracy: 0.6804\n",
      "Epoch 174/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0065 - accuracy: 0.9991 - val_loss: 10.4854 - val_accuracy: 0.6830\n",
      "Epoch 175/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 11.3234 - val_accuracy: 0.6814\n",
      "Epoch 176/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0054 - accuracy: 0.9993 - val_loss: 11.3273 - val_accuracy: 0.6780\n",
      "Epoch 177/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 11.1927 - val_accuracy: 0.6818\n",
      "Epoch 178/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 11.0522 - val_accuracy: 0.6788\n",
      "Epoch 179/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0066 - accuracy: 0.9993 - val_loss: 11.2935 - val_accuracy: 0.6776\n",
      "Epoch 180/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0051 - accuracy: 0.9993 - val_loss: 11.0495 - val_accuracy: 0.6806\n",
      "Epoch 181/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 11.2903 - val_accuracy: 0.6806\n",
      "Epoch 182/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 10.7026 - val_accuracy: 0.6832\n",
      "Epoch 183/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 10.8271 - val_accuracy: 0.6794\n",
      "Epoch 184/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 11.0925 - val_accuracy: 0.6826\n",
      "Epoch 185/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0048 - accuracy: 0.9993 - val_loss: 11.1212 - val_accuracy: 0.6770\n",
      "Epoch 186/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 10.8981 - val_accuracy: 0.6730\n",
      "Epoch 187/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0093 - accuracy: 0.9986 - val_loss: 11.4377 - val_accuracy: 0.6850\n",
      "Epoch 188/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 11.1359 - val_accuracy: 0.6860\n",
      "Epoch 189/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 11.2108 - val_accuracy: 0.6802\n",
      "Epoch 190/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 10.9865 - val_accuracy: 0.6850\n",
      "Epoch 191/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0062 - accuracy: 0.9991 - val_loss: 11.0149 - val_accuracy: 0.6824\n",
      "Epoch 192/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 11.1147 - val_accuracy: 0.6870\n",
      "Epoch 193/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 11.5486 - val_accuracy: 0.6856\n",
      "Epoch 194/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 11.2674 - val_accuracy: 0.6804\n",
      "Epoch 195/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 11.0807 - val_accuracy: 0.6882\n",
      "Epoch 196/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 11.3262 - val_accuracy: 0.6814\n",
      "Epoch 197/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 11.4056 - val_accuracy: 0.6798\n",
      "Epoch 198/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 11.6322 - val_accuracy: 0.6956\n",
      "Epoch 199/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 11.6971 - val_accuracy: 0.6898\n",
      "Epoch 200/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0096 - accuracy: 0.9988 - val_loss: 11.9216 - val_accuracy: 0.6820\n",
      "Epoch 201/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0065 - accuracy: 0.9990 - val_loss: 11.6445 - val_accuracy: 0.6860\n",
      "Epoch 202/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 11.2841 - val_accuracy: 0.6882\n",
      "Epoch 203/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 11.3321 - val_accuracy: 0.6880\n",
      "Epoch 204/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 11.1193 - val_accuracy: 0.6876\n",
      "Epoch 205/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 11.2618 - val_accuracy: 0.6850\n",
      "Epoch 206/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 11.2222 - val_accuracy: 0.6832\n",
      "Epoch 207/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0062 - accuracy: 0.9992 - val_loss: 10.8094 - val_accuracy: 0.6776\n",
      "Epoch 208/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0064 - accuracy: 0.9989 - val_loss: 11.2346 - val_accuracy: 0.6752\n",
      "Epoch 209/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 11.3851 - val_accuracy: 0.6820\n",
      "Epoch 210/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 11.7248 - val_accuracy: 0.6776\n",
      "Epoch 211/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 11.8599 - val_accuracy: 0.6720\n",
      "Epoch 212/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0068 - accuracy: 0.9991 - val_loss: 11.3282 - val_accuracy: 0.6830\n",
      "Epoch 213/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 11.8116 - val_accuracy: 0.6792\n",
      "Epoch 214/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 12.1889 - val_accuracy: 0.6762\n",
      "Epoch 215/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 12.1879 - val_accuracy: 0.6748\n",
      "Epoch 216/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 11.6637 - val_accuracy: 0.6806\n",
      "Epoch 217/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 11.8302 - val_accuracy: 0.6856\n",
      "Epoch 218/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 12.1720 - val_accuracy: 0.6766\n",
      "Epoch 219/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0047 - accuracy: 0.9993 - val_loss: 12.4282 - val_accuracy: 0.6750\n",
      "Epoch 220/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 12.0427 - val_accuracy: 0.6806\n",
      "Epoch 221/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 12.4287 - val_accuracy: 0.6770\n",
      "Epoch 222/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 12.6830 - val_accuracy: 0.6766\n",
      "Epoch 223/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0078 - accuracy: 0.9990 - val_loss: 12.8638 - val_accuracy: 0.6850\n",
      "Epoch 224/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 12.2036 - val_accuracy: 0.6876\n",
      "Epoch 225/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 11.9200 - val_accuracy: 0.6788\n",
      "Epoch 226/1000\n",
      "687/687 [==============================] - 82s 120ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 11.7521 - val_accuracy: 0.6818\n",
      "Epoch 227/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0064 - accuracy: 0.9990 - val_loss: 11.4794 - val_accuracy: 0.6786\n",
      "Epoch 228/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 12.0606 - val_accuracy: 0.6798\n",
      "Epoch 229/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 11.6650 - val_accuracy: 0.6828\n",
      "Epoch 230/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 12.0092 - val_accuracy: 0.6848\n",
      "Epoch 231/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 11.7308 - val_accuracy: 0.6820\n",
      "Epoch 232/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0060 - accuracy: 0.9992 - val_loss: 11.6920 - val_accuracy: 0.6798\n",
      "Epoch 233/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 11.9979 - val_accuracy: 0.6808\n",
      "Epoch 234/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0058 - accuracy: 0.9993 - val_loss: 11.9027 - val_accuracy: 0.6836\n",
      "Epoch 235/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 12.3148 - val_accuracy: 0.6858\n",
      "Epoch 236/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 12.1321 - val_accuracy: 0.6844\n",
      "Epoch 237/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 12.0087 - val_accuracy: 0.6828\n",
      "Epoch 238/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 12.3104 - val_accuracy: 0.6846\n",
      "Epoch 239/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 12.2521 - val_accuracy: 0.6784\n",
      "Epoch 240/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 12.7345 - val_accuracy: 0.6816\n",
      "Epoch 241/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 13.1016 - val_accuracy: 0.6820\n",
      "Epoch 242/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0047 - accuracy: 0.9993 - val_loss: 12.9773 - val_accuracy: 0.6756\n",
      "Epoch 243/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 13.1371 - val_accuracy: 0.6800\n",
      "Epoch 244/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0108 - accuracy: 0.9991 - val_loss: 12.8646 - val_accuracy: 0.6798\n",
      "Epoch 245/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0051 - accuracy: 0.9993 - val_loss: 12.6432 - val_accuracy: 0.6816\n",
      "Epoch 246/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 12.1800 - val_accuracy: 0.6820\n",
      "Epoch 247/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0078 - accuracy: 0.9991 - val_loss: 12.2519 - val_accuracy: 0.6804\n",
      "Epoch 248/1000\n",
      "687/687 [==============================] - 82s 120ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 12.8699 - val_accuracy: 0.6792\n",
      "Epoch 249/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0070 - accuracy: 0.9992 - val_loss: 12.1184 - val_accuracy: 0.6732\n",
      "Epoch 250/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 12.6401 - val_accuracy: 0.6816\n",
      "Epoch 251/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 12.6240 - val_accuracy: 0.6738\n",
      "Epoch 252/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0065 - accuracy: 0.9992 - val_loss: 12.1702 - val_accuracy: 0.6866\n",
      "Epoch 253/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 13.1162 - val_accuracy: 0.6910\n",
      "Epoch 254/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 12.6591 - val_accuracy: 0.6924\n",
      "Epoch 255/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0059 - accuracy: 0.9993 - val_loss: 13.2037 - val_accuracy: 0.6848\n",
      "Epoch 256/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 13.0143 - val_accuracy: 0.6848\n",
      "Epoch 257/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0065 - accuracy: 0.9992 - val_loss: 12.7436 - val_accuracy: 0.6846\n",
      "Epoch 258/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0048 - accuracy: 0.9995 - val_loss: 13.5715 - val_accuracy: 0.6914\n",
      "Epoch 259/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0062 - accuracy: 0.9993 - val_loss: 13.1703 - val_accuracy: 0.6870\n",
      "Epoch 260/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 13.3586 - val_accuracy: 0.6848\n",
      "Epoch 261/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 13.6477 - val_accuracy: 0.6852\n",
      "Epoch 262/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 13.7907 - val_accuracy: 0.6950\n",
      "Epoch 263/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0059 - accuracy: 0.9993 - val_loss: 13.5689 - val_accuracy: 0.6854\n",
      "Epoch 264/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0058 - accuracy: 0.9993 - val_loss: 13.9762 - val_accuracy: 0.6858\n",
      "Epoch 265/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0089 - accuracy: 0.9990 - val_loss: 13.1050 - val_accuracy: 0.6840\n",
      "Epoch 266/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0061 - accuracy: 0.9992 - val_loss: 12.7466 - val_accuracy: 0.6806\n",
      "Epoch 267/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0052 - accuracy: 0.9992 - val_loss: 12.2960 - val_accuracy: 0.6826\n",
      "Epoch 268/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 12.4869 - val_accuracy: 0.6806\n",
      "Epoch 269/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 13.1839 - val_accuracy: 0.6758\n",
      "Epoch 270/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0064 - accuracy: 0.9992 - val_loss: 12.6318 - val_accuracy: 0.6868\n",
      "Epoch 271/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0049 - accuracy: 0.9993 - val_loss: 12.2354 - val_accuracy: 0.6840\n",
      "Epoch 272/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 12.8652 - val_accuracy: 0.6848\n",
      "Epoch 273/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 13.0639 - val_accuracy: 0.6862\n",
      "Epoch 274/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 13.5140 - val_accuracy: 0.6838\n",
      "Epoch 275/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 13.6974 - val_accuracy: 0.6848\n",
      "Epoch 276/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 13.7592 - val_accuracy: 0.6848\n",
      "Epoch 277/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 13.8234 - val_accuracy: 0.6834\n",
      "Epoch 278/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 13.5615 - val_accuracy: 0.6804\n",
      "Epoch 279/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 13.3356 - val_accuracy: 0.6868\n",
      "Epoch 280/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 13.7077 - val_accuracy: 0.6782\n",
      "Epoch 281/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0053 - accuracy: 0.9994 - val_loss: 13.5569 - val_accuracy: 0.6934\n",
      "Epoch 282/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0075 - accuracy: 0.9991 - val_loss: 13.1036 - val_accuracy: 0.6918\n",
      "Epoch 283/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0057 - accuracy: 0.9995 - val_loss: 13.2582 - val_accuracy: 0.6854\n",
      "Epoch 284/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 12.8725 - val_accuracy: 0.6852\n",
      "Epoch 285/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 13.6580 - val_accuracy: 0.6778\n",
      "Epoch 286/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0056 - accuracy: 0.9993 - val_loss: 13.3788 - val_accuracy: 0.6922\n",
      "Epoch 287/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0068 - accuracy: 0.9991 - val_loss: 13.4078 - val_accuracy: 0.6900\n",
      "Epoch 288/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 13.2044 - val_accuracy: 0.6936\n",
      "Epoch 289/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 13.0598 - val_accuracy: 0.6928\n",
      "Epoch 290/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 13.2139 - val_accuracy: 0.6928\n",
      "Epoch 291/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0091 - accuracy: 0.9990 - val_loss: 13.9212 - val_accuracy: 0.6730\n",
      "Epoch 292/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0059 - accuracy: 0.9992 - val_loss: 13.5537 - val_accuracy: 0.6842\n",
      "Epoch 293/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 13.4264 - val_accuracy: 0.6878\n",
      "Epoch 294/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 13.7273 - val_accuracy: 0.6886\n",
      "Epoch 295/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 13.8582 - val_accuracy: 0.6880\n",
      "Epoch 296/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0051 - accuracy: 0.9993 - val_loss: 13.2745 - val_accuracy: 0.6870\n",
      "Epoch 297/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0057 - accuracy: 0.9992 - val_loss: 13.1059 - val_accuracy: 0.6828\n",
      "Epoch 298/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 13.3426 - val_accuracy: 0.6816\n",
      "Epoch 299/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0062 - accuracy: 0.9994 - val_loss: 12.9915 - val_accuracy: 0.6848\n",
      "Epoch 300/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 13.4231 - val_accuracy: 0.6810\n",
      "Epoch 301/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0043 - accuracy: 0.9995 - val_loss: 14.1268 - val_accuracy: 0.6860\n",
      "Epoch 302/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0044 - accuracy: 0.9993 - val_loss: 13.9433 - val_accuracy: 0.6924\n",
      "Epoch 303/1000\n",
      "687/687 [==============================] - 83s 121ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 13.5564 - val_accuracy: 0.6848\n",
      "Epoch 304/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 13.9793 - val_accuracy: 0.6868\n",
      "Epoch 305/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 13.9845 - val_accuracy: 0.6906\n",
      "Epoch 306/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0057 - accuracy: 0.9993 - val_loss: 14.3070 - val_accuracy: 0.6870\n",
      "Epoch 307/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 14.6179 - val_accuracy: 0.6878\n",
      "Epoch 308/1000\n",
      "687/687 [==============================] - 83s 120ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 14.1743 - val_accuracy: 0.6882\n",
      "Epoch 309/1000\n",
      "484/687 [====================>.........] - ETA: 24s - loss: 0.0056 - accuracy: 0.9993"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "model.fit(train_dataset,\n",
    "          validation_data = test_dataset,\n",
    "          epochs=1000, \n",
    "          shuffle=True,\n",
    "          callbacks=[model_checkpoint_callback],\n",
    "          verbose=1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 4.1 multiclass classification using Neural Network Language Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
