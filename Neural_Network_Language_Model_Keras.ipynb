{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Network Language Model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0DI8FyjsdVx",
        "outputId": "b5a93366-e157-4eea-b939-8c1a6a8a200a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbuFnLN9sw3Y",
        "outputId": "a94f2308-9d4e-4de7-f372-6d58aeca2c3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install contractions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting contractions\n",
            "  Downloading https://files.pythonhosted.org/packages/00/92/a05b76a692ac08d470ae5c23873cf1c9a041532f1ee065e74b374f218306/contractions-0.0.25-py2.py3-none-any.whl\n",
            "Collecting textsearch\n",
            "  Downloading https://files.pythonhosted.org/packages/42/a8/03407021f9555043de5492a2bd7a35c56cc03c2510092b5ec018cae1bbf1/textsearch-0.0.17-py2.py3-none-any.whl\n",
            "Collecting pyahocorasick\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/9f/f0d8e8850e12829eea2e778f1c90e3c53a9a799b7f412082a5d21cd19ae1/pyahocorasick-1.4.0.tar.gz (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 18.2MB/s \n",
            "\u001b[?25hCollecting Unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 47.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.0-cp36-cp36m-linux_x86_64.whl size=81701 sha256=46093418470c1acde0973e307279157b46aec2574bc52c2be0b090646ddcf875\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/90/61/87a55f5b459792fbb2b7ba6b31721b06ff5cf6bde541b40994\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: pyahocorasick, Unidecode, textsearch, contractions\n",
            "Successfully installed Unidecode-1.1.1 contractions-0.0.25 pyahocorasick-1.4.0 textsearch-0.0.17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkOXU-vzsym_",
        "outputId": "cff67bc8-b9b8-4d7e-b525-6080d18de35c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import np_utils\n",
        "import contractions\n",
        "import numpy as np\n",
        "import re\n",
        "import tqdm\n",
        "import unicodedata\n",
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Version:  2.3.0\n",
            "Eager mode:  True\n",
            "Hub version:  0.10.0\n",
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAtLHNfoQItI"
      },
      "source": [
        "#### Load preprocessed data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws45aHzTs3N_"
      },
      "source": [
        "import pickle\n",
        "##load pre-processed data\n",
        "with open('/content/gdrive/My Drive/upwork/train_content_new.pkl','rb') as f:\n",
        "  train_content = pickle.load(f)\n",
        "with open('/content/gdrive/My Drive/upwork/train_rating_new.pkl','rb') as f:\n",
        "  train_rating = pickle.load(f)\n",
        "with open('/content/gdrive/My Drive/upwork/test_content_new.pkl','rb') as f:\n",
        "  test_content = pickle.load(f)\n",
        "with open('/content/gdrive/My Drive/upwork/test_rating_new.pkl','rb') as f:\n",
        "  test_rating = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI83nQfOQTD_"
      },
      "source": [
        "Basic Text Pre-processing\n",
        "We do minimal text pre-processing here since we are using deep learning models and not count-based methods. Steps include the following:\n",
        "\n",
        "\n",
        "\n",
        "Converting accented characters\n",
        "\n",
        "*   Fixing contractions\n",
        "*   Removing special characters\n",
        "*   Converting accented characters\n",
        "\n",
        "Note : For some models we don't use any pre-processing like BERT!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mTkSy9ss5CX"
      },
      "source": [
        "def remove_accented_chars(text):\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    return text\n",
        "\n",
        "def pre_process_corpus(docs):\n",
        "    norm_docs = []\n",
        "    for doc in tqdm.tqdm(docs):\n",
        "        doc = doc.translate(doc.maketrans(\"\\n\\t\\r\", \"   \"))\n",
        "        doc = doc.lower()\n",
        "        doc = remove_accented_chars(doc)\n",
        "        doc = contractions.fix(doc)\n",
        "        # lower case and remove special characters\\whitespaces\n",
        "        doc = re.sub(r'[^a-zA-Z0-9\\s]', ' ', doc, re.I|re.A)\n",
        "        doc = re.sub(' +', ' ', doc)\n",
        "        doc = doc.strip()  \n",
        "        norm_docs.append(doc)\n",
        "    return norm_docs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZJWrwtLs7BX",
        "outputId": "b01340a6-8202-4e72-e23d-45bdaf0b3b9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "train_content = pre_process_corpus(train_content)\n",
        "test_content = pre_process_corpus(test_content)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 458266/458266 [01:00<00:00, 7564.45it/s]\n",
            "100%|██████████| 50919/50919 [00:06<00:00, 7513.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 6s, sys: 861 ms, total: 1min 7s\n",
            "Wall time: 1min 7s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjCygD2UQqO5"
      },
      "source": [
        "### convert target variable to one hot encoding since its a multiclass classification problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68PGKPSItC9W"
      },
      "source": [
        "train_rating = np_utils.to_categorical(train_rating)\n",
        "test_rating = np_utils.to_categorical(test_rating)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g589Jj2FQ2O-"
      },
      "source": [
        "### Building input pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nclae92wtOJn"
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_content, train_rating))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs9iBYorQCUq"
      },
      "source": [
        "### Build a NNLM Embedding Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT8u-Y-CtR6n"
      },
      "source": [
        "model = \"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\"\n",
        "hub_layer = hub.KerasLayer(model, output_shape=[128], input_shape=[], \n",
        "                           dtype=tf.string, trainable=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM3eFA5_RBGO"
      },
      "source": [
        "### Build Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8Yab_ZytvTW",
        "outputId": "bea3810c-8171-4182-b551-e040e13f419b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(hub_layer)\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.15))\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.15))\n",
        "model.add(tf.keras.layers.Dense(6, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer (KerasLayer)     (None, 128)               124642688 \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 774       \n",
            "=================================================================\n",
            "Total params: 124,676,486\n",
            "Trainable params: 124,676,486\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoShnp9IRJLx"
      },
      "source": [
        "### load prerained weights if available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIGmiAlyYAsT"
      },
      "source": [
        "epochs = 100\n",
        "filepath=\"/content/gdrive/My Drive/upwork/weights/model.h5\"\n",
        "model.load_weights(filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnoBfgauRVbo"
      },
      "source": [
        "### Define callbacks "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnmA0-JzuMTn"
      },
      "source": [
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_acc',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
        "                                      patience=3,\n",
        "                                      restore_best_weights=True,\n",
        "                                      verbose=1)\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtmsRuX2RgE3"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "supB9JsAWCP2",
        "outputId": "fb1dd872-4150-42f3-8c9d-2e47ba598d60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  model.fit(train_dataset,\n",
        "          validation_steps = 0.05,\n",
        "          epochs=5, \n",
        "          shuffle=True,\n",
        "          callbacks=[es,model_checkpoint_callback],\n",
        "          verbose=1)\n",
        "  model.save(filepath)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "7161/7161 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.9833WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7161/7161 [==============================] - 535s 75ms/step - loss: 0.0512 - accuracy: 0.9833\n",
            "Epoch 2/5\n",
            "7161/7161 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 0.9832WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7161/7161 [==============================] - 536s 75ms/step - loss: 0.0515 - accuracy: 0.9832\n",
            "Epoch 3/5\n",
            "7161/7161 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 0.9842WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7161/7161 [==============================] - 540s 75ms/step - loss: 0.0488 - accuracy: 0.9842\n",
            "Epoch 4/5\n",
            "7161/7161 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 0.9838WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7161/7161 [==============================] - 537s 75ms/step - loss: 0.0494 - accuracy: 0.9838\n",
            "Epoch 5/5\n",
            "7161/7161 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9839WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7161/7161 [==============================] - 537s 75ms/step - loss: 0.0496 - accuracy: 0.9839\n",
            "Epoch 1/5\n",
            "7161/7161 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9840WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7161/7161 [==============================] - 533s 74ms/step - loss: 0.0496 - accuracy: 0.9840\n",
            "Epoch 2/5\n",
            "1396/7161 [====>.........................] - ETA: 7:08 - loss: 0.0473 - accuracy: 0.9843"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liI76AE-Zyp6"
      },
      "source": [
        "model.save('/content/gdrive/My Drive/upwork/weights/new_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}